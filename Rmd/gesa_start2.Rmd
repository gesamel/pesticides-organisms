---
title: "Untitled"
author: "Gesa Amelung"
date: "7 November 2017"
output:
  pdf_document: default
  html_document: default
bibliography: rpc_lit.bib
editor_options: 
  chunk_output_type: console
  
---

# Introduction

Changes in the communty of diatoms in response to several environmental factors have been well studied. Thereby, changes in diatom community structure  can be taken as a proxy for environmental pollution with e.g. nutrients. However, the response of the diatom community to pesticides has not been well studied so far. Especially the response to herbicides is of special concern since they are the type of herbicides that are most toxic to diatoms. 

In this study, monitoring data from lotic waterbodies in Germany from the years 2005 - 2012 is used to perform Correspondance Analysis (CA). With ordination via CA, the main trend of variation can be visualized. With subsequent Canonical Correspondance Analysis (CCA), this trend can be connected to environmental descriptors. Those environmental descriptors are represented by a dataset of physical-chemical data and herbicide data sampled in lotic waterbodies of Germany as well.

# Data Analysis

## Setup

The following packages and the data base access script was loaded.

```{r setup, echo=TRUE, message=FALSE}
## load packages
require(RPostgreSQL)
require(sf)
require(knitr)
require(mapview)
require(data.table)
require(dplyr)
require(vegan)
require(ggplot2)
require(gridExtra)
require(stringr)

## switch
online = FALSE

## load access data
path = getwd()
source(file.path(path, 'amelung_access.R'))
```

## Loading data

### Pesticide data

The pesticide data was loaded including the samples, the sites and geographic information of the sites.

```{r load-PSM-data, echo=TRUE, eval=FALSE, message=FALSE}
if (online) {
  drv = dbDriver("PostgreSQL")
  con = dbConnect(drv, dbname = DBname, user = DBuser, host = DBhost, port = DBport, password = DBpassword)
  
  psm_sites_geo = st_read_db(con, query = "SELECT *
                                           FROM views.psm_sites_2005")
  psm_sites = as.data.frame(psm_sites_geo)
  psm_sam = dbGetQuery(con, "SELECT *
                                 FROM views.psm_samples_2005 sam
                                 JOIN phch.phch_variables var
                                ON var.variable_id = sam.variable_id")
  psm_sam = psm_sam[ ,-c(16, 24)] # delete duplicate rows
  
  dbDisconnect(con)
  dbUnloadDriver(drv)
  
  saveRDS(psm_sites_geo, file.path('cache', 'psm_sites_geo.rds'))
  saveRDS(psm_sites, file.path('cache', 'psm_sites.rds'))
  saveRDS(psm_sam, file.path('cache', 'psm_sam.rds'))
} else {
  psm_sites_geo <- readRDS(file.path('cache', 'psm_sites_geo.rds'))
  psm_sites <- readRDS(file.path('cache', 'psm_sites.rds'))
  psm_sam <- readRDS(file.path('cache', 'psm_sam.rds'))
}

psm_sam = psm_sam %>%
  filter(psm_type == 'herbicide' & date > '2004-12-31')
## AS: when the script is finished we could also consider applying it to all pesticides

# Create column for year
psm_sam$year <- format(psm_sam$date, '%Y')
psm_sam$month <- format(psm_sam$date, '%m')
psm_sam$day <- format(psm_sam$date, '%j')
```

### Diatom data
```{r load-diatom-data, echo=TRUE, message=FALSE}
if (online) {
  drv = dbDriver("PostgreSQL")
  con = dbConnect(drv, dbname = DBname, user = DBuser, host = DBhost, port = DBport, password = DBpassword)
  # dia_sites = dbGetQuery(con, "SELECT * FROM dia.dia_sites") ##AS: no need to extra load this
  dia_sites_geo = st_read_db(con, query = "SELECT * FROM dia.dia_sites")
  dia_sites = as.data.frame(dia_sites_geo)
  dia_sam = dbGetQuery(con, "SELECT *
                         FROM dia.dia_samples
                         WHERE date > '2004-12-31'
                         ")
  dbDisconnect(con) ##AS: close beore doing the belwo changes
  dbUnloadDriver(drv)
  
  saveRDS(dia_sites_geo, file.path('cache', 'dia_sites_geo.rds'))
  saveRDS(dia_sites, file.path('cache', 'dia_sites.rds'))
  saveRDS(dia_sam, file.path('cache', 'dia_sam.rds'))

} else {
  
  dia_sites_geo = readRDS(file.path('cache', 'dia_sites_geo.rds'))
  dia_sites = readRDS(file.path('cache', 'dia_sites.rds'))
  dia_sam = readRDS(file.path('cache', 'dia_sam.rds'))
}

# Create column for species name only. Add "sp." to those names that only have genera 
dia_sam$species <- gsub('[[:punct:]]', '', dia_sam$taxon) # remove punctuation characters
dia_sam$species <- gsub('([a-z]+)\\s([a-z]+)(.+)*', '\\1 \\2', dia_sam$species) # reduce to two strings (removes: 'var', 'form')
dia_sam$species <- ifelse(str_count(dia_sam$species, pattern = '\\s') == 0,
                          paste0(dia_sam$species, ' sp.'),
                          dia_sam$species)

# table(str_count(dia_sam$species, pattern = '\\s')) # count space characters (only 1s should be left) ##AS: tests for two name taxa

# Create column for genus name
dia_sam$genus <- sub("^(\\S*).*", "\\1", dia_sam$taxon)

# Create column for year
dia_sam$year <- format(dia_sam$date, '%Y')
dia_sam$month <- format(dia_sam$date, '%m')
dia_sam$day <- format(dia_sam$date, '%j')
```

### River network
```{r load-river-network}
if (online) {
  drv = dbDriver("PostgreSQL")
  con = dbConnect(drv, dbname = DBname, user = DBuser, host = DBhost, port = DBport, password = DBpassword)
  
  streams = st_read_db(con, query = "SELECT * FROM spatial.gewaessertyp")
  
  dbDisconnect(con)
  dbUnloadDriver(drv)
  
  saveRDS(streams, file.path('cache', 'streams.rds'))

} else {
  
  streams = readRDS(file.path('cache', 'streams.rds'))
}
```

### Load physical-chemical data
```{r load-phch-data, echo=TRUE, message=FALSE}
if (online) {
  drv = dbDriver("PostgreSQL")
  con = dbConnect(drv, dbname = DBname, user = DBuser, host = DBhost, port = DBport, password = DBpassword)

  phch_sam = dbGetQuery(con, "SELECT *
                              FROM phch.phch_samples sam
                              LEFT JOIN phch.phch_variables var ON var.variable_id = sam.variable_id
                                  WHERE date > '2004-12-31' AND date < '2016-01-01'")
  dbDisconnect(con)
  dbUnloadDriver(drv)
  
  saveRDS(phch_sam, file.path('cache', 'phch_sam.rds'))
} else {
  phch_sam = readRDS(file.path('cache', 'phch_sam.rds'))
}

phch_sam = phch_sam[ , -c(16, 24)] # removes duplicated unit, variable_id entries

# Get only data that are not psm or psm = herbicide
#phch_sam <- phch_sam[phch_sam$psm_type%in%c("herbicide", ""),] # 9,620,631 datapoints
# get onlly data that are no chemicals or are herbicides.
phch_sam <- phch_sam %>%
  filter(casnr =="" | psm_type=="herbicide")
# 5,268,995 datapoints
nrow(phch_sam[phch_sam$casnr=="",])

phch_sam$year <- format(phch_sam$date, '%Y')  # Create column for year
phch_sam$month <- format(phch_sam$date, '%m') # Create column for month
phch_sam$day <- format(phch_sam$date, '%j')   # Create column for day of the year

```

### Load ec50 data

```{r load-ec50-data, echo=TRUE, message=FALSE}
if (online) {
  drv = dbDriver("PostgreSQL")
  con = dbConnect(drv, dbname = DBname, user = DBuser, host = DBhost, port = DBport, password = DBpassword)

ec50 = dbGetQuery(con, "SELECT casnr, subst_name, ec50f_al4896_fin
                                FROM phch.phch_ec50_fin
                  ")
  dbDisconnect(con)
  dbUnloadDriver(drv)
  
  saveRDS(ec50, file.path('cache', 'ec50.rds'))
} else {
  ec50 = readRDS(file.path('cache', 'ec50.rds'))
}
```

Join physica-chemical data with EC50 data.
```{r join-ec50}
# Join phch with ec50 to include casnr
phch_sam = left_join(phch_sam, ec50, by = "casnr")

# Remove all rows that are pesticides but don't have a ec50f_al4896_fin  entry
# Keep all rows that have a EC50 valueor that are no pesticides.

phch_sam = phch_sam %>%
  filter(!ec50f_al4896_fin=="" | psm == FALSE)

```


## Data preparation

For the CCA later on, a dataset was created containing only diatom samples where herbicides were measured at the same site in the same month (`dia_sam_cca`). For the CA, all samples were retained in order to have a larger dataset  (`dia_sam`).

```{r join-on-site-year, echo=TRUE, message=FALSE}
# Diatom data

dia_sam_cca <- semi_join(dia_sam, phch_sam[phch_sam$psm==TRUE,], by = c("site_id", "month"))
nrow(dia_sam_cca)

##AS: like this you can keep it an sf-object:
##AS: generally you can handle sf-Objects with dplyr like data.frames and tibbles
#dia_sites_cca <- dia_sites_geo[ dia_sites_geo$site_id %in% psm_sites_geo$site_id, ]
```


### Usage of cover data as quantitative variable
In most cases, diatom cover was measured instead of abundance. Therefore, rows where abundance was measured were deleted. Instead, the cover data is used as the quantitative variable in the following analyses. The deletion of irrelevant rows was performed for the datasets for CA and CCA seperately.

```{r delete-abundance-data, echo=TRUE, message=FALSE}
dia_sam <- dia_sam[!is.na(dia_sam$cover), ]
dia_sam <- dia_sam[,-6]    #delete column with abundance data

dia_sam_cca <- dia_sam_cca[!is.na(dia_sam_cca$cover), ]
dia_sam_cca <- dia_sam_cca[,-6] 
```

## Visualization of the sampling frequency

Sampling days and sampling events per year.

```{r sampling-days-per-year, echo=TRUE, message=FALSE}
## Number of samples

# Count number of samples per month and year
sample_count_ym = dia_sam %>%
  group_by(year, month) %>%
  summarise(N = n()) %>%
   as.data.frame()

# Count number of samples per year
sample_count_y = dia_sam %>%
  group_by(year) %>%
  summarise(N = n()) %>%
   as.data.frame()

## Number of sampling events

# Count number of sampling events (id_pn) per year
event_count_y <- dia_sam %>% 
  group_by(year) %>%
  summarise(N = n_distinct(id_pn))  %>%
   as.data.frame()

# Count number of sampling events per month and year
event_count_ym <- dia_sam %>% 
  group_by(year, month) %>%
  summarise(N = n_distinct(id_pn))  %>%
   as.data.frame()

## Plots

# Plot: Number of samples per month and year
gg1 <- ggplot(sample_count_ym, aes(y = N, x = month)) +
  geom_point() +
  facet_wrap( ~ year) +
  ggtitle ("number of diatom samples per month and year")
gg1

# Plot: Number of sampling events per month and year
gg2 <- ggplot(event_count_ym, aes(y = N, x = month)) +
  geom_point() +
  facet_wrap( ~ year) +
  ggtitle ("number of diatom sampling events per month and year")
gg2

## Plot: Sampling counts per year & Event counts per year
gg3 <- ggplot(dia_sam, aes(x=year)) +
  geom_bar() +
  labs(title="diatom samples per year", x = "year", y = "sample counts")

gg4 <- ggplot(event_count_y, aes(x=year, y = N)) +
  geom_bar(stat="identity") +
  labs(title="events per year", x = "year", y = "event counts")

grid.arrange(gg3, gg4, ncol=2)

# number of samples per month
gg5 <- ggplot(dia_sam, aes(x=month)) +
  geom_bar() +
  labs(title="diatom samples per month", x = "month", y = "number of samples")
gg5
ggsave(gg5, width = 4, height = 4, filename = "figures/n_month.png")

# number of samples per month and year
gg6 <- ggplot(sample_count_ym, aes(y = N, x = year)) +
  geom_point() +
  facet_wrap( ~ month) +
  ggtitle ("number of diatom samples per year and month")
gg6
ggsave(gg6, width = 10, height = 10, filename = "figures/n_my.png")

sam_ym <- dcast(sample_count_ym, year ~ month, fill = "-")

# number of sampes per day
gg07 <- ggplot(dia_sam[dia_sam$month=="07",], aes(x=day)) +
  geom_bar() +
  ylim(0, 1750) +
  labs(title="diatom samples per day - July", x = "day", y = "number of samples")

gg08 <- ggplot(dia_sam[dia_sam$month=="08",], aes(x=day)) +
  geom_bar() +
  ylim(0, 1750) +
  labs(title="diatom samples per day - August", x = "day", y = "number of samples")

gg09 <- ggplot(dia_sam[dia_sam$month=="09",], aes(x=day)) +
  geom_bar() +
  ylim(0, 1750) +
  labs(title="diatom samples per day - September", x = "day", y = "number of samples")

gg7 <- grid.arrange(gg07, gg08, gg09, ncol=3)
ggsave(gg7, width = 22, height = 10, filename = "figures/n_july_sept.png")

```

It seems like the distribution of samples and sampling events is very similar. This means that on every sampling day and event, a similar number of samples was taken. 

One month of the early and the late application season, respectively, were to be chosen for further analysis. Even though most samples were available for the month August, to compare July and September seemed more suitable. 

```{r herbicides-sampling-overview, echo=TRUE, message=FALSE}
psm_count_ym = phch_sam %>%
  filter(psm == TRUE) %>%
  group_by(year, month) %>%
  summarise(N = n()) %>%
   as.data.frame()

psm_gg1 <- ggplot(phch_sam[phch_sam$psm==TRUE,], aes(x=month)) +
  geom_bar() +
  labs(title="herbicide samples per month", x = "month", y = "number of samples")
psm_gg1
ggsave(psm_gg1, width = 4, height = 4, filename = "figures/n_psm_month.png")

psm_gg2<- ggplot(psm_count_ym, aes(y = N, x = year)) +
  geom_point() +
  facet_wrap( ~ month) +
  ggtitle ("number of herbicide samples per year and month")
psm_gg2
ggsave(psm_gg2, width = 10, height = 10, filename = "figures/n_psm_my.png")

psm_gg3 <- ggplot(phch_sam[phch_sam$psm==TRUE,], aes(x=year)) +
  geom_bar() +
  labs(title="herbicide samples per year", x = "year", y = "sample counts")
psm_gg3
```

Herbicides were sampled in all month with a high intensity. Generally, less samples were taken in the winter months. According to this continuous high amount of data, no months have to be excluded based on that. The amount of diatom data would be the more conservative proxy to gudge which months are appropriate to use for further analyses.
In 2015, almost no herbicide samples were taken. Also, the year 2014 was not so frequently sampled.

```{r remove-months}
dia_sam = dia_sam %>%
  filter(month %in% c("07", "08", "09"))

dia_sam_cca = dia_sam_cca %>%
  filter(month %in% c("07", "08", "09"))
  
```

## Taxon frequency
[@Marchant.2002] suggests to remove rare species as only common species produce information that can reliably be linked to present environmental gradients. [@Cao.2001] suggests the removal of rare species if samples were taken over a large spatial scale which holds true for the present dataset. Furthermore, Chi-square distance, which is the distance measure used in CA and CCA, gives more weight to rare species. Due to this reason, [@Legendre.2012] suggest to remove rare species from the analysis. Here, 4 datasets are created: Species and genera that occur at less than 20 % of the sites were removed, respectively and species and genera that occur in less than 5 % of the samples were removed, respectively.

The analysis was done for both, species and genus data and therefore, all procedures were performed for species data and genus data seperately from here on. According to (@Rimet.2012), analysis with a taxonomic resolution of genus performs as well as a resolution of species level in many cases. Similarly, (@Larras.2014) found that diatom sensitivity to herbicides can be attributed to their phylogeny. They reported that centric and araphid diatoms (Thalassiosirales and Fragilariales, respectively
) were most sensitive to the herbicides whereas pennates (Cymbellales, Naviculales and Bacillariales)
) were more robust.

```{r  delete-rare-taxa, echo=TRUE, message=FALSE}
## Rare = taxa that occur at less than 5 % of the samples
sampleN = length(unique(dia_sam$id_pn))
n_sp <- length(unique(dia_sam$species))
n_ge <- length(unique(dia_sam$genus))

## Rare genera
dia_sam_ge = dia_sam %>%
  group_by(genus) %>%
  mutate(perc = n_distinct(id_pn) / sampleN) %>%
  arrange(-perc) %>%
  filter(perc >= 0.05)

# precentage of genera remaining after removal of rare genera
n_ge_abu <-length(unique(dia_sam_ge$genus)) #44
n_ge_abu
n_ge_abu/n_ge*100 # 57.1 %

# Plot
dia_sam_N_ge = dia_sam_ge %>%
       group_by(genus) %>%
       summarise(N=n())
plot(density(dia_sam_N_ge$N), main="Genus density")

## Rare species
dia_sam_sp = dia_sam %>%
  group_by(species) %>%
  mutate(perc = n_distinct(id_pn) / sampleN) %>%
  arrange(-perc) %>%
  filter(perc >= 0.05)

# precentage of genera remaining after removal of rare genera
n_sp_abu <-length(unique(dia_sam_sp$species)) # 153
n_sp_abu
n_sp_abu/n_sp*100 # 17.7 %

# Plot
dia_sam_N_sp = dia_sam_sp %>%
       group_by(species) %>%
       summarise(N=n())
plot(density(dia_sam_N_sp$N), main="Species density")

## Rare genera of dia_sam_cca dataset
sampleN_cca = length(unique(dia_sam_cca$id_pn))
n_ge_cca <- length(unique(dia_sam_cca$genus))

## Rare genera
dia_sam_ge_cca = dia_sam_cca %>%
  group_by(genus) %>%
  mutate(perc = n_distinct(id_pn) / sampleN_cca) %>%
  arrange(-perc) %>%
  filter(perc >= 0.05)

# precentage of genera remaining after removal of rare genera
n_ge_abu_cca <-length(unique(dia_sam_ge_cca$genus)) #43
n_ge_abu_cca
n_ge_abu_cca/n_ge_cca*100 # 59.7 %

# Plot
dia_sam_N_ge_cca = dia_sam_ge_cca %>%
       group_by(genus) %>%
       summarise(N=n())
plot(density(dia_sam_N_ge_cca$N), main="Genus density")


```

## Transform data to get from long to wide data

For the subsequent analysis, the data needed to be transformend from long to wide format. If several combinations of (`site_id`)  and (`species`) were present, the 95th percentile was taken to aggregate them. Further, the first column was stored as rowname. The aggregation was first performed over all years and over all months seperately.

#### graphical inspection of years
```{r ggplot-year}
# overview plots

length(unique(dia_sam$site_id)) ##AS: 1194

gr1 = ggplot(dia_sam, aes(y = site_id, x = month)) +
  geom_raster(aes(fill = year)) +
  facet_wrap( ~ year)
gr1

ggsave(gr1, width = 8, height = 5, filename = '/tmp/dia_sam.png')

gr2 = ggplot(dia_cov, aes(y = site_id, x = year)) +
  geom_raster(aes(fill = log10(cover+1)))
gr2
##AS: Maybe skip 2013/14?

gr3 = ggplot(dia_cov) +
  geom_raster(aes(y = site_id, x = day, fill = year))
gr3
```

### Aggregation per month

The data were aggregated per month by the 95th percentile of the cover. The data were then transformed from long to wide format.

Diatom communities follow a seasonal succession which might be more prominent than the interanual succession. (@Hausmann.2007) showed that for lakes, the spring and summer conditions had a strong impact on the diatom composition and productivity that was stronger than the impact of changing annual mean temperatures. Similarly,  (@Kirilova.2008) observed a seasonal succession of diatoms in  lakes. The predominant diatoms in winter and spring were of the genus *Stephanodiscus* while species of the genera *Stephanodiscus*, *Fragilaria*, and *Nitzschia* were the most abundant diatoms in summer and autumn. To account for this seasonal variability of diatom composition, it seemed reasonable to summarize the diatom data for each month over all years.
 
#### Species

```{r cast-species, echo=TRUE, message=FALSE}
dia_aggr_sp <- dia_sam_sp %>% 
  group_by(month, species, site_id) %>%
  summarise(mean = mean(cover),
            perc95 = quantile(cover, 0.95, na.rm = TRUE),
            total = n()) %>%
  arrange(species)

# Store single years as seperate elements of a list
dia_aggr_split_sp <- split(dia_aggr_sp, dia_aggr_sp$month)

cast_sp <- lapply(dia_aggr_split_sp, function(x) dcast(x, site_id ~ species, value.var="perc95", fill = 0))

# Take the first column and store it as a rowname, afterwards, delete the first column.
cast_sp <- lapply(cast_sp,
                     function(x) { rownames(x) <- x[,1];
                                   x[,1] <- NULL;
                                   x })

# Remove rows where the row sum is zero.
cast_sp <- lapply(cast_sp,
       function(x) { x[rowSums(x) > 0,] })
```

#### Genus

```{r cast-genus, echo=TRUE, message=FALSE}
dia_aggr_ge <- dia_sam_ge %>% 
  group_by(month, genus, site_id) %>%
  summarise(mean = mean(cover),
            perc95 = quantile(cover, 0.95, na.rm = TRUE),
            total = n()) %>%
  arrange(genus)

# Store single months as seperate elements of a list
dia_aggr_split_ge <- split(dia_aggr_ge, dia_aggr_ge$month)

cast_ge <- lapply(dia_aggr_split_ge, function(x) dcast(x, site_id ~ genus, value.var="perc95", fill = 0))

# Take the first column and store it as a rowname, afterwards, delete the first column.
cast_ge <- lapply(cast_ge,
                     function(x) { rownames(x) <- x[,1];
                                   x[,1] <- NULL;
                                   x })

# Remove rows where the row sum is zero.
cast_ge <- lapply(cast_ge,
       function(x) { x[rowSums(x) > 0,] })
```

#### Genus - CCA dataset

```{r cast-genus-cca, echo=TRUE, message=FALSE}
dia_aggr_ge_cca <- dia_sam_ge_cca %>% 
  group_by(month, genus, site_id) %>%
  summarise(mean = mean(cover),
            perc95 = quantile(cover, 0.95, na.rm = TRUE),
            total = n()) %>%
  arrange(genus)

# Store single months as seperate elements of a list
dia_aggr_split_ge_cca <- split(dia_aggr_ge_cca, dia_aggr_ge_cca$month)

cast_ge_cca <- lapply(dia_aggr_split_ge_cca, function(x) dcast(x, site_id ~ genus, value.var="perc95", fill = 0))

# Take the first column and store it as a rowname, afterwards, delete the first column.
cast_ge_cca <- lapply(cast_ge_cca,
                     function(x) { rownames(x) <- x[,1];
                                   x[,1] <- NULL;
                                   x })

# Remove rows where the row sum is zero.
cast_ge_cca <- lapply(cast_ge_cca,
       function(x) { x[rowSums(x) > 0,] })
```

### DCA

A Detrended Correspondance Analysis (DCA) was performed in order to decide whether it is appropriate to conduct a unimodal gradient method. DCA was introduced by (@Hill.1980). If the length of the first DCA axis, scaled in units of standard deviations (S.D.), is > 4 S.D. a complete species turnover can be assumed and a unimodal gradient method is appropriate to use. A linear gradient method would be more appropriate for a length of the first axes < 3 S.D., indicating an incomplete change of species composition. For an axis length between 3 and 4, both types of methods are appropriate to use (@Leps.2003).

#### Species

```{r dca-species, echo=TRUE, message=FALSE}
lapply(cast_sp, function(x) {decorana(x)})
lapply(cast_sp, function(x) {plot(decorana(x), display="both")})
```
The legth of the first axis is > 3 S.D. in all months and therefore, a unimodal gradient can be assumed for all months.

#### Genus
```{r dca-genus, echo=TRUE, message=FALSE}
lapply(cast_ge, function(x) {decorana(x)})
lapply(cast_ge, function(x) {plot(decorana(x), display="both")})
```

Also for genus data, the length of the first axis is > 3 S.D. in all months and therefore, a unimodal gradient can be assumed for all months.

#### Genus - CCA
```{r dca-genus-cca-dataset, echo=TRUE, message=FALSE}
lapply(cast_ge_cca, function(x) {decorana(x)})
lapply(cast_ge_cca, function(x) {plot(decorana(x), display="both")})
```

For genus data for the cca, the length of the first axis is > 4 S.D. in all months and therefore, a unimodal gradient can be assumed for all months.

## CA

Correspondance Analysis (CA) was used to determine the major trends of variation of the diatom community before including any environmental data. CA is an ordination method and hence reduces data of multidimensional space to a 2- or 3-dimensional representation with minimal loss of information. The dimensions included in the ordination plot are the ones with the highest amount of variance and thus display the greatest part of variability of the data. The advantage of CA is that, by using weighted averages ordination, sites and species are ordered at the same time into the same space. In the ordination plot, similar communities and species are close together while dissimilar communities and species are further apart.

### Species

```{r  ca-species, echo=TRUE, message=FALSE}
# conduct CA
ca_sp <-lapply(cast_sp, function(x) {cca(x)})

# Compute summary of CA results to inspect proportion of variance explained by each axis.
lapply(ca_sp, function(x) {summary(x)})
```

```{r  plot-ca-species, echo=TRUE, message=FALSE}
# Compute biplots without names
lapply(cast_sp, function(x) {plot(cca(x), scaling=2)})

# Biplots with species names
dianame_long_sp <- lapply(cast_sp, function(x) colnames(x))

dianame_sp <- lapply(cast_sp, function(x) make.cepnames(names(x)))
stems_sp <- lapply(cast_sp, colSums)

for (i in 1:length(dianame_sp)) {
  plot(ca_sp[[i]], dis="sp", type="n") #red crosses = species, dots = sites
  orditorp(ca_sp[[i]], dis="sp", lab=dianame_sp[[i]], priority=stems_sp[[i]],
           pcol="red", pch="+")
}
```
It seems like there are not one or two main factors explaining the variance in diatom composition but many since the fraction of cumulative explained variation is also not very high when considering several axes.
I.e.
July: cum explained variance of 1.+2. axes:0.12000
August: cum explained variance of 1.+2. axes: 0.09192
September: cum explained variance of 1. + 2. axes: 0.11570

### Genus

```{r  ca-genus, echo=TRUE, message=FALSE}
# conduct CA
ca_ge <-lapply(cast_ge, function(x) {cca(x)})

# Compute summary of CA results to inspect proportion of variance explained by each axis.
lapply(ca_ge, function(x) {summary(x)})
```

The cumulated explained variance of the first two axes is above 20 % in all months which is a much higher value than when taking species for the CA. Therefore, it might make more sense to proceed analysis with genus data instead of with species data.
I.e.: 
July: 1.+2. CA: 19.9 % of cumulative explaned variance
August: 1.+2. CA: 19.8 % of cumulative explaned variance
September:  1.+2. CA: 23.5 % of cumulative explaned variance

```{r  plot-ca-genus, echo=TRUE, message=FALSE}
# Compute biplots without names
lapply(cast_ge, function(x) {plot(cca(x), scaling=2)})

# Biplots with species names
dianame_long_ge <- lapply(cast_ge, function(x) colnames(x))

# dianame_m_ge <- lapply(cast_months_ge, function(x) make.cepnames(names(x)))
stems_ge <- lapply(cast_ge, colSums)

for (i in 1:length(dianame_long_ge)) {
  plot(ca_ge[[i]], dis="sp", type="n") #red crosses = species, dots = sites
  orditorp(ca_ge[[i]], dis="sp", lab=dianame_long_ge[[i]], priority=stems_ge[[i]],
           pcol="red", pch="+")
}

```

Does not work yet
```{r}
# make plots
ca_list_ge = list()
for (i in 1:length(dianame_long_ge)) {
 p = plot(ca_ge[[i]], dis="sp", type="n") 
  orditorp(ca_ge[[i]], dis="sp", lab=dianame_long_ge[[i]], priority=stems_ge[[i]],
           pcol="red", pch="+")
  ca_list_ge[[i]] = p
}

# save plots
for (i in 1:3) {
  file_name = paste("ca_plot_ge_", i, ".png", sep="")
  png(file_name)
  print(ca_list_ge[[i]])
  dev.off()
}
```

## Environmental data

# cast_ge_cca is the diatom data to use for this part.

All physical-chemical data were deleted that were not taken at the same site and in the same month as a diatom sample.
--> Nochmal neu berechnen wenn weitere Monate rausgeschmissen wurden.
```{r join-phch, echo=TRUE, message=FALSE}
phch_sam <- semi_join(phch_sam, dia_sam_cca, by =c("site_id","month")) 
```

### Keep only certain environmental variables

```{r envi-variables, echo=TRUE, message=FALSE}
phch_list = phch_sam %>%
  filter(psm == FALSE) %>%
  distinct(name) %>%
  arrange(name)
phch_list

nrow(phch_sam[phch_sam$name=="Elektrische LeitfÃ¤higkeit (20Â°C)", ]) #2133
nrow(phch_sam[phch_sam$name=="Elektrische LeitfÃ¤higkeit (25Â°C)", ]) #5034
# More data available for conductivity at 25 degree

# o-Phosphat-P,ortho-Phosphat
nrow(phch_sam[phch_sam$name=="o-Phosphat-P", ]) #2391
nrow(phch_sam[phch_sam$name=="ortho-Phosphat", ]) #2070 #PO4 3-
# Is that the same just with a different name? Can I then combine them? if yes --> Just rename one variable to the other

# Landwirtschaft (atkis_perc) --> Not found.

phch_sam <- phch_sam %>%
  filter(psm == 'TRUE' | name %in% c("Wassertemperatur", "pH-Wert (Feld)", "Elektrische LeitfÃ¤higkeit (25Â°C)", "SauerstoffsÃ¤ttigung", "gesamter organisch gebundener Kohlenstoff", "Gesamt-Stickstoff" , "o-Phosphat-P", "ortho-Phosphat" ))

# Rename o-Phosphat-P cells
# phch_sam$name[phch_sam1$name=="o-Phosphat-P"] <- "ortho-Phosphat"

# Rename all names
phch_sam$name[phch_sam$name=="Wassertemperatur"] <- "temperature"
phch_sam$name[phch_sam$name=="pH-Wert (Feld)"] <- "pH"
phch_sam$name[phch_sam$name=="Elektrische LeitfÃ¤higkeit (25Â°C)"] <- "conductivity"
phch_sam$name[phch_sam$name=="SauerstoffsÃ¤ttigung"] <- "oxygen saturation"
phch_sam$name[phch_sam$name=="gesamter organisch gebundener Kohlenstoff"] <- "TOC"
phch_sam$name[phch_sam$name=="Gesamt-Stickstoff"] <- "tot-N"
```

    - Landwirtschaft (atkis_perc)
    - Temperature +
    - pH +
    - maxTU/Monat (2 wichtigsten Monate)
    - conductivity +
    - Sauerstoffgehalt +
    - tot-P
    - tot-N +
    - TOC +



### calculate TU from EC50
```{r Tcalculate-TU, echo=TRUE, message=FALSE}
# TU = log10(concentration of compound / EC50)
# sumTU + maxTU




```



```{r select-envi-variables, echo=TRUE, message=FALSE}
herb_list = phch_sam %>%
  filter(psm_type == 'herbicide') %>%
  distinct(name) %>%
  arrange(name)

nrow(herb_list)

phch <- phch_sam %>%
  filter(psm == 'TRUE' | name %in% c("Nitit", "Nitrat-Stickstoff", "Kalium", "Chlorid", "Nitrat", "Gesamt-Phosphor", "Sauerstoffgehalt", "Gesamt-Stickstoff", "Stickstoff", "pH-Wert (Feld)", "Ammonium-Stickstoff", "BSB5", "Nitrit-Stickstoff", "Natrium", "Sulfat", "Ammonium", "Abfluss", "Stickstoff", "Hydrogenkarbonat", "Eisen", "Wassertemperatur", "Magnesium", "Phosphor", "Chemischer Sauerstoffgehalt"))

# 6,768,652 observations
phch_sam <- phch_sam[! phch_sam$value_fin =="0",]   # if value is zero, then limit of quantification was not reached
nrow(phch_sam)
# 481,178 observations

# Change order of columns
#envi = envi[ ,c(1:2,7, 3:6)]

##########################################
# Convert water temperature from celsius to kelvin
#envi <- envi %>%
#  ifelse(name %in% "Wassertemperatur", value_fin + 273.15, value_fin)

#envi_K <- envi %>%
#  filter(grep("Wassertemperatur", name)) %>%
#  mutate(value_fin2 = value_fin + 273.15)

#envi_K <- envi %>%
#  mutate(value_fin2 = ifelse(grepl("Wassertemperatur", name), value_fin + 273.15, #ifelse(grepl(!"Wassertemperatur", name), value_fin)))

# none of these work yet..

```

Aggregate data over all years and within years. Then, transform data from long to wide format.
```{r  transformation-95th-envi, echo=TRUE, message=FALSE}

# Aggreagate over all years
# setDF(dia_cov)
envi_aggr <- envi %>%
  group_by(name, site_id) %>%
  summarise(mean = mean(value_fin),
            perc95 = quantile(value_fin, 0.95, na.rm = TRUE),
            total = n()) %>%
  arrange(name)

# Transform data into wide format
envi_cast <- dcast(envi_aggr, site_id ~ name, value.var ="perc95", fill=0)

# Make site_id column into rowname
rownames(envi_cast) <- (envi_cast[,1])
envi_cast <- envi_cast[,-1]

# aggregate for all years seperately
envi_aggr_year <- envi %>%
  group_by(year, name, site_id) %>%
  summarise(mean = mean(value_fin),
            perc95 = quantile(value_fin, 0.95, na.rm = TRUE),
            total = n()) %>%
  arrange(name)

# Store single years as seperate elements of a list
envi_aggr_split <- split(envi_aggr_year, envi_aggr_year$year)
envi_aggr_split[["2005"]] # check out structure

# Transform data from long to wide format
envi_cast_years <- lapply(envi_aggr_split, function(x) dcast(x, site_id ~ name, value.var="perc95", fill = 0))
names(envi_cast_years)
envi_cast_years[["2014"]] # checkt out structure

# Change rownames using the first column
rownames(envi_cast_years[["2005"]]) <- (envi_cast_years[["2005"]][,1])
rownames(envi_cast_years[["2006"]]) <- (envi_cast_years[["2006"]][,1])
rownames(envi_cast_years[["2007"]]) <- (envi_cast_years[["2007"]][,1])
rownames(envi_cast_years[["2008"]]) <- (envi_cast_years[["2008"]][,1])
rownames(envi_cast_years[["2009"]]) <- (envi_cast_years[["2009"]][,1])
rownames(envi_cast_years[["2010"]]) <- (envi_cast_years[["2010"]][,1])
rownames(envi_cast_years[["2011"]]) <- (envi_cast_years[["2011"]][,1])
rownames(envi_cast_years[["2012"]]) <- (envi_cast_years[["2012"]][,1])
rownames(envi_cast_years[["2013"]]) <- (envi_cast_years[["2013"]][,1])
rownames(envi_cast_years[["2014"]]) <- (envi_cast_years[["2014"]][,1])
rownames(envi_cast_years[["2015"]]) <- (envi_cast_years[["2015"]][,1])

# Delete column "site_id" of each row object
envi_cast_years <- lapply(envi_cast_years, function(x) {x["site_id"] <- NULL;x})
```

# Check for collinearity. First, over the years 2005-2012 (years for which enough diatom data is available). Then, check all years seperately.
```{r collinearity-check, echo=TRUE, message=FALSE}
## Check for collinearity between explanatory data
# 
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- abs(cor(x, y, use = "complete.obs"))
  txt <- format(c(r, 0.123456789), digits = digits)[1]
  txt <- paste(prefix, txt, sep = "")
  if (missing(cex.cor)) 
    cex <- 0.8/strwidth(txt)
  
  test <- cor.test(x,y)
  # borrowed from printCoefmat
  Signif <- symnum(test$p.value, corr = FALSE, na = FALSE,
                   cutpoints = c(0, 0.05, 0.1, 1),
                   symbols = c("*", ".", " "))
  
  text(0.5, 0.5, txt, cex = cex * r)
  text(.8, .8, Signif, cex = cex, col = 2)
}
pairs(envi_cast[ ,1:10], 
      lower.panel = panel.smooth, upper.panel = panel.cor)

# Figure margins too large to show all the envi-variables.

# Shows correlation matrix. --> Too large to be displayed completely
cor(envi_cast, use = "complete.obs")

# VIF
sort(vif(envi_cast))

```

