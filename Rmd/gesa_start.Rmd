---
title: "Untitled"
author: "Gesa Amelung"
date: "7 November 2017"
output:
  pdf_document: default
  html_document: default
editor_options: 
  chunk_output_type: console
---

## Setup

Load the following packages and load the data base access scipt:

```{r setup, echo=TRUE, message=FALSE}
## load packages
require(RPostgreSQL)
require(sf)
require(knitr)
#AS: added some used packages to the top:
require(mapview)
require(data.table)
require(dplyr)

## load access data
path = getwd() #AS: necessary to make it run for me
#path = 'D:/Gesa/Dokumente/Ecotoxicology/RPC'
source(file.path(path, 'Rmd', 'R', 'amelung_access.R'))

```

## Loading data

Query PostgresSQL data base: bfg_monitoring
Cannot load full psm_samples so far, maybe internet is too weak.. Set LIMIT 100

```{r load-PSM-data, echo=TRUE, message=FALSE}
drv = dbDriver("PostgreSQL")
con = dbConnect(drv, dbname = DBname, user = DBuser, host = DBhost, port = DBport, password = DBpassword)

psm_sites = dbGetQuery(con, "SELECT *
                             FROM views.psm_sites_2005
                       ")
psm_samples = dbGetQuery(con, "SELECT *
                               FROM views.psm_samples_2005 sam
                               JOIN phch.phch_variables var 
                              ON var.variable_id = sam.variable_id
                         ORDER BY sam.sample_id
                         LIMIT 1000") #AS: hier ist noch ein Limit von 1000. Warum?
psm_samples = psm_samples[ ,-c(16, 24)]

psm_samples = psm_samples %>%
  filter(psm_type == 'herbicide')

psm = dbGetQuery(con, "SELECT *
                               FROM views.psm_samples_2005 sam
                               
                         ORDER BY sam.sample_id
                         LIMIT 1000") #AS: hier ist noch ein Limit von 1000. Warum?

dbDisconnect(con)
dbUnloadDriver(drv)
```

```{r load-diatom-data, echo=TRUE, message=FALSE}
drv = dbDriver("PostgreSQL")
con = dbConnect(drv, dbname = DBname, user = DBuser, host = DBhost, port = DBport, password = DBpassword)

dia_sites = dbGetQuery(con, "SELECT * FROM dia.dia_sites")
dia_sites_geo = st_read_db(con, query = "SELECT * FROM dia.dia_sites LIMIT 10")
dia_sam = dbGetQuery(con, "SELECT *
                       FROM dia.dia_samples
                       WHERE date > '2004-12-31'
                       ")
# mapview(dia_sites_geo)

dbDisconnect(con)
dbUnloadDriver(drv)
```

Load physical-chemical data
```{r load-phch-data, echo=TRUE, message=FALSE}
drv = dbDriver("PostgreSQL")
con = dbConnect(drv, dbname = DBname, user = DBuser, host = DBhost, port = DBport, password = DBpassword)

# there are more sites than psm_sites (including only pesticides) though they aren't necessary for us.
phch_samples = dbGetQuery(con, "SELECT *
                                FROM phch.phch_samples sam
                                LEFT JOIN phch.phch_variables var ON var.variable_id = sam.variable_id
                                WHERE var.name IN ('Wassertemperatur', 'Sulfat');")
phch_samples = phch_samples[ , -c(16, 24)] #AS! removes duplicated unit, variable_id entries
# 596477 observations
dbDisconnect(con)
dbUnloadDriver(drv)
```


## Compare both sample datasets
Want to compare tables on year and site_id:
Extract year from date.
```{r  extract-year-from-date, echo=TRUE, message=FALSE}
drv = dbDriver("PostgreSQL")
con = dbConnect(drv, dbname = DBname, user = DBuser, host = DBhost, port = DBport, password = DBpassword)

sam_tab = dbGetQuery(con, " SELECT dsam.site_id, dsam.date, psam.date, 
                    EXTRACT(YEAR FROM dsam.date) AS sam_year,
                    EXTRACT(YEAR FROM psam.date) AS psm_year
                     FROM dia.dia_samples AS dsam
                     INNER JOIN views.psm_samples_2005 AS psam 
                     ON dsam.site_id = psam.site_id
                    LIMIT 100");

# Not really helpful yet, I keep it anyways, just in case.
dbDisconnect(con)
dbUnloadDriver(drv)

head(dia_sam)
dia_sam$year = format(dia_sam$date, '%Y')

##AS: Do such tasks only in R and use SQL only for loading the data. Makes it more portable
#1) E.g with data.table:
setDT(phch_samples)
phch_samples[ , .(start = min(date),
                  end = max(date)), by = site_id]
# .() in data.table is the same as list()
# in data.table you have always three arguments (i - select rows, j - do aggregation/filtering, by - by group)
# in this case:
# i is empty
# j is in .()
# and by is site_id

#2) same with dplyr
setDF(phch_samples)
phch_samples %>%
  group_by(site_id) %>%
  summarise(start = min(date),
            end = max(date))
```

Select all diatom samples where environmental variable data was measured at the same site in the same year and where herbicides were detected.

```{r  join-relevant-variables, echo=TRUE, message=FALSE}
##AS: Das ist viel zu kompliziert und langasam. mach den join in R und nicht mit SQL.
# e.g. with data.table:

setDT(dia_sam)
setDT(phch_samples)
# merge.data.table is used
dia = merge(dia_sam, phch_samples, by = .EACHI, all.x = TRUE)
# or
dia2 = merge(phch_samples, dia_sam, all.y = TRUE, by = 'site_id')

##AS: column: year + site_id als Identifikationsspalte für den merge
head(dia_sam)

# oder mit dplyr (was dir lieber ist):
dia3 = left_join(dia_sam, phch_samples)



drv = dbDriver("PostgreSQL")
con = dbConnect(drv, dbname = DBname, user = DBuser, host = DBhost, port = DBport, password = DBpassword)

join = dbGetQuery(con, " SELECT DISTINCT ON (dsam.site_id, dsam.date, dsam.taxon) psam.sample_id, dsam.site_id, dsam.date, taxon, iz_n, cover, var.psm_type, var.name
                   FROM dia.dia_samples AS dsam
                   INNER JOIN views.psm_samples_2005 AS psam
                   ON dsam.site_id = psam.site_id
                   INNER JOIN phch.phch_variables var 
                   ON var.variable_id = psam.variable_id 
                     WHERE var.psm_type = 'herbicide'
                   AND ((dsam.date BETWEEN '2005-01-01' AND '2005-12-31'
                   AND psam.date BETWEEN '2005-01-01' AND '2005-12-31')
                OR (dsam.date BETWEEN '2006-01-01' AND '2006-12-31'
                   AND psam.date BETWEEN '2006-01-01' AND '2006-12-31')
                OR (dsam.date BETWEEN '2007-01-01' AND '2007-12-31'
                   AND psam.date BETWEEN '2007-01-01' AND '2007-12-31')
                OR (dsam.date BETWEEN '2008-01-01' AND '2008-12-31'
                   AND psam.date BETWEEN '2008-01-01' AND '2008-12-31')
               OR (dsam.date BETWEEN '2009-01-01' AND '2009-12-31'
                   AND psam.date BETWEEN '2009-01-01' AND '2009-12-31')
                OR (dsam.date BETWEEN '2010-01-01' AND '2010-12-31'
                   AND psam.date BETWEEN '2010-01-01' AND '2010-12-31')
                 OR (dsam.date BETWEEN '2011-01-01' AND '2011-12-31'
                   AND psam.date BETWEEN '2011-01-01' AND '2011-12-31')
                 OR (dsam.date BETWEEN '2012-01-01' AND '2012-12-31'
                   AND psam.date BETWEEN '2012-01-01' AND '2012-12-31')
                 OR (dsam.date BETWEEN '2013-01-01' AND '2013-12-31'
                   AND psam.date BETWEEN '2013-01-01' AND '2013-12-31')
                OR (dsam.date BETWEEN '2014-01-01' AND '2014-12-31'
                   AND psam.date BETWEEN '2014-01-01' AND '2014-12-31')
                OR (dsam.date BETWEEN '2015-01-01' AND '2015-12-31'
                   AND psam.date BETWEEN '2015-01-01' AND '2015-12-31'))
                   ORDER BY dsam.date, dsam.site_id, dsam.taxon
                   ")
# results in 45980 observations

# Add column with year
join$year <- as.numeric(format(join$date, '%Y'))

# Add column with month
join$month <- as.numeric(format(join$date, '%m'))

# Shorten taxon name
join$taxon <- sub("^(\\S*\\s+\\S+).*", "\\1", join$taxon)

# Delete species where cover =0
join <- join[!join$cover=="0", ]

# join$cover <- round(join$cover, digits = 4)a
dia_sam$taxon
head(dia_sam)
nrow(dia_sam[ dia_sam$cover == 0, ])
nrow(dia_sam[ !is.na(dia_sam$iz_n), ])


#AS: Art-Spalte:
# taxon -> Eolimna minima
# Nitzschia -> Nitzschia sp.
# Nitzschia capitellata var. capitellata -> Nitzschia capitellata

# Genus-Spalte:
# Nitzschia -> Nitzschia
# Nitzschia capitellata var. capitellata -> Nitschia



dbDisconnect(con)
dbUnloadDriver(drv)
```

## Taxon frequency
Are there any rare species? Marchant (2002) suggests to remove rare species and Cao et al.(2001) suggests this if samples were taken over a large spatial scale which holds true for the present data. So the question is what a suitable definition for rare species is. E.g. species that occur in only 1 sample. Different approaches were performed in the literature.

```{r  taxon-frequency, echo=TRUE, message=FALSE}
#AS: data.table is also very nice to do different tasks successively (each within [])
setDT(dia)
dia200 = dia[ , .N, by = taxon][order(-N)][N >= 200] #AS : 200 is just an example

#AS: dplyr approach:
setDF(dia)
dia200 = dia_sam %>%
  group_by(taxon) %>%
  summarise(N = n()) %>%
  arrange(-N) %>%
  filter(N > 1)

taxa_fin = dia200$taxon

dia_sam[ dia_sam$taxon %in% taxa_fin, ]

plot(density(dia200$N))
# taxon list
dia200$taxon

# or:
dia %>%
  count(taxon) %>%
  arrange(-n) %>%
  filter(n >= 200)


taxon_count <- table(join$taxon)
summary(taxon_count)
taxon_count <-as.data.frame(taxon_count)
taxon_count <- taxon_count[order(taxon_count$Freq),]
head(taxon_count)
freqn <- nrow(taxon_count) # 730
freqn
freq3 <- nrow(taxon_count[taxon_count$Freq<5,]) # 297 taxa only present less than 5 times.
freq3
freq2 <- nrow(taxon_count[taxon_count$Freq<3,]) # 207 taxa only present less than 3 times.
freq2
freq1 <- nrow(taxon_count[taxon_count$Freq<2,]) # 120 taxa only present once.
freq1

hist(taxon_count$Freq, breaks = 50)   

# relative frequency of species that are only present once.
freq1/freqn*100       # 16.4 % of all species are only present once.
freq1/nrow(join)*100 # 0.26 % of all Samples-site combinations represent a species that was sampled only once.

##AS: Waht do you suggest?
```
The distribution of species frequency is very left-skewed. Most species are present in less than ~200 samples and few are present in more than 200 samples.

## Get at list of taxa
```{r  taxon-list, echo=TRUE, message=FALSE}
taxa_list <-sort(unique(join$taxon)) # list of al species in the dataset
nrow(as.data.frame(taxa_list)) #800 different species are in the dataset

genus_list <- sapply(strsplit(as.character(taxa_list), ' '), '[', 1) # keeps only genus name
genus_list <-sort(unique(genus_list)) # list of all genera in the dataset
nrow(as.data.frame(genus_list)) # 70 different genera are in the dataset
```

Delete rows where abundance was measured instead of cover
```{r  subset-data-years, echo=TRUE, message=FALSE}

join_cov <- select(join, taxon, sample_id, site_id, year, month, cover)
join_cov <- join_cov[complete.cases(join_cov), ]
#AS: better is.na()
join_cov[!is.na(join_cov$cover), ]
# 39583 of 45980 entries remain
join_cov <- join_cov[!join_cov$cover=="0", ]
# 39270 entries remain
```

# Subset data for specific years
```{r  subset-data-years, echo=TRUE, message=FALSE}
# within R and not via SQL query (quicker if join is already in envrironment)

##AS: no need to do this. Like this you have way to many objects in your envrionment.
# you can always subset the data.frame when needed
phch_samples[ date <= '2007-01-01' ] #! when data.table it works without comma. Otherwiose use comma after the string

head(dia_sam)
dia_sam %>%
  group_by(year)

join2005 <- subset(join, date < as.Date("2006-01-01"))
join2006 <- subset(join, (date < as.Date("2007-01-01"))&(date > as.Date("2005-12-31")))
join2007 <- subset(join, (date < as.Date("2008-01-01"))&(date > as.Date("2006-12-31")))
join2008 <- subset(join, (date < as.Date("2009-01-01"))&(date > as.Date("2007-12-31")))
join2009 <- subset(join, (date < as.Date("2010-01-01"))&(date > as.Date("2008-12-31")))
join2010 <- subset(join, (date < as.Date("2011-01-01"))&(date > as.Date("2009-12-31")))
join2011 <- subset(join, (date < as.Date("2012-01-01"))&(date > as.Date("2010-12-31")))
join2012 <- subset(join, (date < as.Date("2013-01-01"))&(date > as.Date("2011-12-31")))
join2013 <- subset(join, (date < as.Date("2014-01-01"))&(date > as.Date("2012-12-31")))
join2014 <- subset(join, (date < as.Date("2015-01-01"))&(date > as.Date("2013-12-31")))
join2015 <- subset(join, date > as.Date("2014-12-31"))

```

# Transform data to get from long to wide data
Prepare data for transformation.
```{r  prepare-data-for-transformation, echo=TRUE, message=FALSE}
##AS: not needed. See steps before. Only perform these tasks only for one object/data.frame


# Since iz_n (species abundance) is often empty,  I instead choose cover for abundance data.

##AS: this does all the work
dia_sam = dia_sam[ ,c(1:6,8,7)]

# Create proper data format
dia05 <- data.frame(join2005$taxon, join2005$site_id, join2005$date, join2005$year, join2005$month, as.numeric(join2005$cover))
dia06 <- data.frame(join2006$taxon, join2006$site_id, join2006$date, join2006$year, join2006$month, as.numeric(join2006$cover))
dia07 <- data.frame(join2007$taxon, join2007$site_id, join2007$date, join2007$year, join2007$month, as.numeric(join2007$cover))
dia08 <- data.frame(join2008$taxon, join2008$site_id, join2008$date, join2008$year, join2008$month, as.numeric(join2008$cover))
dia09 <- data.frame(join2009$taxon, join2009$site_id, join2009$date, join2009$year, join2009$month, as.numeric(join2009$cover))
dia10 <- data.frame(join2010$taxon, join2010$site_id, join2010$date, join2010$year, join2010$month, as.numeric(join2010$cover))
dia11 <- data.frame(join2011$taxon, join2011$site_id, join2011$date, join2011$year, join2011$month, as.numeric(join2011$cover))
dia12 <- data.frame(join2012$taxon, join2012$site_id, join2012$date, join2012$year, join2012$month, as.numeric(join2012$cover))
dia13 <- data.frame(join2013$taxon, join2013$site_id, join2013$date, join2013$year, join2013$month, as.numeric(join2013$cover))
dia14 <- data.frame(join2014$taxon, join2014$site_id, join2014$date, join2014$year, join2014$month, as.numeric(join2014$cover))
dia15 <- data.frame(join2015$taxon, join2015$site_id, join2015$date, join2015$year, join2015$month, as.numeric(join2015$cover))
# In 2013, there is only one observation. For 2014 and 2015, there are no observations at all.
# I will ignore them from now on.

# Rename the columns
names(dia05) <- c("taxon", "site_id", "date", "year", "month", "cover" )
names(dia06) <- c("taxon", "site_id", "date", "year", "month", "cover" )
names(dia07) <- c("taxon", "site_id", "date", "year", "month", "cover" )
names(dia08) <- c("taxon", "site_id", "date", "year", "month", "cover" )
names(dia09) <- c("taxon", "site_id", "date", "year", "month", "cover" )
names(dia10) <- c("taxon", "site_id", "date", "year", "month", "cover" )
names(dia11) <- c("taxon", "site_id", "date", "year", "month", "cover" )
names(dia12) <- c("taxon", "site_id", "date", "year", "month", "cover" )


# How many NAs are (in the the column cover) each year?
sum(is.na(dia05$cover)) #1   # from 1704
sum(is.na(dia06$cover)) #0   
sum(is.na(dia07$cover)) #0
sum(is.na(dia08$cover)) #246 # from 4949
sum(is.na(dia09$cover)) #981 # from 10581
sum(is.na(dia10$cover)) #0   
sum(is.na(dia11$cover)) #0
sum(is.na(dia12$cover)) #5165 # from 8055

head(dia_sam)
dia_sam$year = format(dia_sam$date, '%Y')

dia_sam %>%
  group_by(year) %>%
  filter(is.na(cover)) %>%
  summarise(N = n())

# Delete rows with missing values
dia05 <- dia05[complete.cases(dia05), ]
dia08 <- dia08[complete.cases(dia08), ]
dia09 <- dia09[complete.cases(dia09), ]
dia12 <- dia12[complete.cases(dia12), ]

# Delete rows where cover =0
dia05 <- dia05[!dia05$cover=="0", ]
dia06 <- dia06[!dia06$cover=="0", ]
dia07 <- dia07[!dia07$cover=="0", ]
dia08 <- dia08[!dia08$cover=="0", ]
dia09 <- dia09[!dia09$cover=="0", ]
dia10 <- dia10[!dia10$cover=="0", ]
dia11 <- dia11[!dia11$cover=="0", ]
dia12 <- dia12[!dia12$cover=="0", ]
```

Transform data from long to wide format. Take the mean for aggregation if several combinations of site_id and species are present.
```{r  transformation-mean, echo=TRUE, message=FALSE}

##AS: If you want to get the mean of cover for each site and taxon you can do this
# data.table:
# yopu can do multiple aggregations in j!!!
setDT(dia)
dia[ ,
     j = .(mean = mean(cover),
           perc5 = quantile(cover, 0.05, na.rm = TRUE),
           min = min(cover),
           .N), # N gives you the total number
     by = .(taxon, site_id)][order(taxon)]

# or dplyr
setDF(dia)
dia %>%
  group_by(taxon, site_id) %>%
  summarise(mean = mean(cover),
            perc5 = quantile(cover, 0.05, na.rm = TRUE),
            total = n()) %>%
  arrange(taxon)



# Aggregate with reshape2
# require(reshape2)
# cast05a <- dcast(dia05, taxon + date ~ site_id, fill = 0)

# Like this, same species appear several times if it was sampled on different sites on
# several dates in the year.


# cast05 <- dcast(dia05, site_id ~ taxon, fill = 0) # length/amount of presence
# cast05 <- dcast(dia05, site_id ~ taxon, fill = 0, fun.aggregate = mean) # mean of cover
# cast05 <- dcast(dia05, site_id ~ taxon, fill = 0, min) # min of cover

#  In 2013 there is only one diatomeen sample and none in the years 2014 and 2015.
# (That meet the criteria that herbicides were sampled in the same year at the same site.)

# Aggregate with data.table
# If combination appears several times, an aggregation function has to be chosen to combine them into one number.
# Choose either mean, min or calculate the 5th percentile.
require(data.table)

# Take the mean for aggregation

##AS: List introduction:
test = list(dia_sam, iris, dia_sam, 1, c('test', 'test2'), list(1,2))
lapply(test, head) # list
test[[2]]
lapply(dia_sam, head) #data.frame (is list)
dia_sam[1, ]
dia_sam[ ,2]

cast05<- data.table::dcast(dia_sam, site_id ~ taxon, fill=0, fun=mean)
##AS: Multiple arguments in aggregation fiunction
cast05<- data.table::dcast(dia_sam, site_id ~ taxon, fill=0, fun=function(x) quantile(x, 0.05))
cast06<- data.table::dcast(dia06, site_id ~ taxon, fill=0, fun=mean)
cast07<- data.table::dcast(dia07, site_id ~ taxon, fill=0, fun=mean)
cast08<- data.table::dcast(dia08, site_id ~ taxon, fill=0, fun=mean)
cast09<- data.table::dcast(dia09, site_id ~ taxon, fill=0, fun=mean)
cast10<- data.table::dcast(dia10, site_id ~ taxon, fill=0, fun=mean)
cast11<- data.table::dcast(dia11, site_id ~ taxon, fill=0, fun=mean)
cast12<- data.table::dcast(dia12, site_id ~ taxon, fill=0, fun=mean)

```

Take the minimum value for aggregation.
```{r  transformation-min, echo=TRUE, message=FALSE}
# Take the minimum value for aggregation
cast05<- data.table::dcast(dia05, site_id ~ taxon, fill=0, fun=min)
cast06<- data.table::dcast(dia06, site_id ~ taxon, fill=0, fun=min)
cast07<- data.table::dcast(dia07, site_id ~ taxon, fill=0, fun=min)
cast08<- data.table::dcast(dia08, site_id ~ taxon, fill=0, fun=min)
cast09<- data.table::dcast(dia09, site_id ~ taxon, fill=0, fun=min)
cast10<- data.table::dcast(dia10, site_id ~ taxon, fill=0, fun=min)
cast11<- data.table::dcast(dia11, site_id ~ taxon, fill=0, fun=min)
cast12<- data.table::dcast(dia12, site_id ~ taxon, fill=0, fun=min)
```

Take the 5th percentile for aggregation.
```{r  transformation-5th, echo=TRUE, message=FALSE}
# Calculating the 5th percentile of each cover entry
##AS: use one object and one command for this
# like above but with an additional year grouping variable

setDT(dia)
dia$year = format(dia$date, '%Y')
dia[ ,year := format(date, '%Y') ] # data.table way
dia[ ,
     j = .(mean = mean(cover),
           perc5 = quantile(cover, 0.05, na.rm = TRUE),
           min = min(cover),
           .N), # N gives you the total number
     by = .(taxon, site_id, year)][order(site_id, taxon)]

# or dplyr:
setDF(dia)
dia_sam$year = format(dia_sam$date, '%Y')
perc5 = function(x) quantile(x, 0.05, na.rm = TRUE)
dia_sam %>%
  group_by(site_id, year) %>%
  summarise_at('cover', funs(mean, min, perc5))


##AS: split data.frame into multiple data.frames and store in list
dia_sam_year_list = split(dia_sam, dia_sam$year)
dia_sam_year_list[[1]]


require(dplyr)


cov5th_05 <- select(join_cov, year, taxon,site_id, cover) %>%
  filter(year==2005) %>%
  group_by(site_id, taxon) %>%
  summarise('5 %' = quantile(cover, probs=0.05))  %>%
  as.data.frame()

cov5th_06 <- select(join_cov, year, taxon,site_id, cover) %>%
  filter(year==2006) %>%
  group_by(site_id, taxon) %>%
  summarise('5 %' = quantile(cover, probs=0.05))  %>%
  as.data.frame()

cov5th_07 <- select(join_cov, year, taxon,site_id, cover) %>%
  filter(year==2007) %>%
  group_by(site_id, taxon) %>%
  summarise('5 %' = quantile(cover, probs=0.05))  %>%
  as.data.frame()

cov5th_08 <- select(join_cov, year, taxon,site_id, cover) %>%
  filter(year==2008) %>%
  group_by(site_id, taxon) %>%
  summarise('5 %' = quantile(cover, probs=0.05))  %>%
  as.data.frame()

cov5th_09 <- select(join_cov, year, taxon,site_id, cover) %>%
  filter(year==2009) %>%
  group_by(site_id, taxon) %>%
  summarise('5 %' = quantile(cover, probs=0.05))  %>%
  as.data.frame()

cov5th_10 <- select(join_cov, year, taxon,site_id, cover) %>%
  filter(year==2010) %>%
  group_by(site_id, taxon) %>%
  summarise('5 %' = quantile(cover, probs=0.05))  %>%
  as.data.frame()

cov5th_11 <- select(join_cov, year, taxon,site_id, cover) %>%
  filter(year==2011) %>%
  group_by(site_id, taxon) %>%
  summarise('5 %' = quantile(cover, probs=0.05))  %>%
  as.data.frame()

cov5th_12 <- select(join_cov, year, taxon,site_id, cover) %>%
  filter(year==2012) %>%
  group_by(site_id, taxon) %>%
  summarise('5 %' = quantile(cover, probs=0.05))  %>%
  as.data.frame()


cast05 <-data.table::dcast(cov5th_05, site_id ~ taxon, fill =0)
cast06 <-data.table::dcast(cov5th_06, site_id ~ taxon, fill =0)
cast07 <-data.table::dcast(cov5th_07, site_id ~ taxon, fill =0)
cast08 <-data.table::dcast(cov5th_08, site_id ~ taxon, fill =0)
cast09 <-data.table::dcast(cov5th_09, site_id ~ taxon, fill =0)
cast10 <-data.table::dcast(cov5th_10, site_id ~ taxon, fill =0)
cast11 <-data.table::dcast(cov5th_11, site_id ~ taxon, fill =0)
cast12 <-data.table::dcast(cov5th_12, site_id ~ taxon, fill =0)

```
 
 Remove the site information. Do this for all three aggregation methods.
```{r  remove-site-information, echo=TRUE, message=FALSE}
# Do this for all three methods:
# removal of site information
cast05 <-cast05[, -1] 
cast06 <-cast06[, -1]
cast07 <-cast07[, -1] 
cast08 <-cast08[, -1]
cast09 <-cast09[, -1] 
cast10 <-cast10[, -1]
cast11 <-cast11[, -1] 
cast12 <-cast12[, -1]
```

Removal of rare species.
```{r  remove-rare-species, echo=TRUE, message=FALSE}
# presence-absence transformation to calculate species number per site

##AS: also, as above no need for multiple objects

require(vegan)
cast05_pa <-decostand(cast05, "pa") 
cast06_pa <-decostand(cast06, "pa")
cast07_pa <-decostand(cast07, "pa")
cast08_pa <-decostand(cast08, "pa")
cast09_pa <-decostand(cast09, "pa")
cast10_pa <-decostand(cast10, "pa")
cast11_pa <-decostand(cast11, "pa")
cast12_pa <-decostand(cast12, "pa")


# calculate sum per species
spec_sum05 <- apply(cast05_pa,2,sum)
# sort(spec_sum05)
spec_sum06 <- apply(cast06_pa,2,sum)
# sort(spec_sum06)
spec_sum07 <- apply(cast07_pa,2,sum)
# sort(spec_sum07)
spec_sum08 <- apply(cast08_pa,2,sum)
spec_sum09 <- apply(cast09_pa,2,sum)
spec_sum10 <- apply(cast10_pa,2,sum)
# sort(spec_sum10)
spec_sum11 <- apply(cast11_pa,2,sum)
# sort(spec_sum11)
spec_sum12 <- apply(cast12_pa,2,sum)


# remove species that occur at less than 2 sites
# spec_sum needs to be calculated with number of presence data and here continued with cover data
spec_fin05 <- cast05[, ! spec_sum05 <2]
#sort(apply(spec_fin05, 2, max))   #check if it worked
spec_fin06 <- cast06[, ! spec_sum06 <2]
# sort(apply(spec_fin06, 2, max))
spec_fin07 <- cast07[, ! spec_sum07 <2]
# sort(apply(spec_fin07, 2, max))
spec_fin08 <- cast08[, ! spec_sum08 <2]
spec_fin09 <- cast09[, ! spec_sum09 <2]
spec_fin10 <- cast10[, ! spec_sum10 <2]
# sort(apply(spec_fin10, 2, max))
spec_fin11 <- cast11[, ! spec_sum11 <2]
# sort(apply(spec_fin11, 2, max))
spec_fin12 <- cast12[, ! spec_sum12 <2]

```

# DCA
Conduct DCA to see if axis length indicates unimodal response..
```{r  dca, echo=TRUE, message=FALSE}
require(vegan)
# axis lenght = SD. For axis length < 3, linear analysis should be used, for axis length >3, unimodal analysis should be performed.
# If presence-absence data is used: DCA1 length = 2.5
# If cover data (mean) is used: DCA1 length = 3.6 --> unimodal approach would be fine.

# Don't use decorana-values.
spec_dca05<- decorana(spec_fin05)
spec_dca05 #DCA1 length = 3.65 (mean);  = 3.62 (min); = 3.2 (5%)
# summary(spec_dca05, digits=3, origin=TRUE, display="both")

plot(spec_dca05, display="both") 
# crosses=species, points=sites
# shnam <- make.cepnames(names(spec_fin)) #abbreaviation of Latin names

spec_dca06<- decorana(spec_fin06)
spec_dca06 #DCA1 length = 7.48 (mean); = 7.57 (min); = 7.57 (5%)
plot(spec_dca06, display="both")

spec_dca07<- decorana(spec_fin07)
spec_dca07 #DCA1 length = 4.83 (mean); =4.72 (min); = 4.72
plot(spec_dca07, display="both")

spec_dca08<- decorana(spec_fin08)   # many samples deleted before
spec_dca08 #DCA1 length = 4.85 (mean); = 4.85 (min); = 4.85 (5%)
plot(spec_dca08, display="both")

spec_dca09<- decorana(spec_fin09)   # many samples deleted before
spec_dca09 #DCA1 length = 2.39 (mean); = 2.39; = 2.4 (5 %)
plot(spec_dca09, display="both")

spec_dca10<- decorana(spec_fin10)
spec_dca10 #DCA1 length = 4.33 (mean); 4.34 (min); = 4.34 (5%)
plot(spec_dca10, display="both")

spec_dca11<- decorana(spec_fin11)
spec_dca11 #DCA1 length = 6.19 (mean); = 6.09 (min); = 6.09 (5%)
plot(spec_dca11, display="both")

spec_dca12<- decorana(spec_fin12)
spec_dca12 #DCA1 length = 3.77 (mean); = 3.7 (min); = (5%) = 3.70
plot(spec_dca11, display="both")

# Conducting unimodal analysis would be okay for all years except for 2009.
# No big difference between taken the mean or the minimum of the cover values.
```

## Visualization of the sampling frequency
Sampling days/sampling events per year
```{r sampling-days-per-year, echo=TRUE, message=FALSE}
##AS: from here it's way too much code below:
# You can create the same result by just a few lines:

dia_sam$month = format(dia_sam$date, '%m')
require(ggplot2)
## all rows
dia_overview = as.data.table(dia_sam)[ , .N, by = .(year, month)]

ggplot(dia_overview, aes(y = N, x = month)) +
  geom_point() +
  facet_wrap( ~ year)


# sample_id
# count number of sampling_id per year
require(dplyr)

##AS: Mind the LIMIT when you load in the data via PostgreSQL
event_counts <- dia %>% ##AS: changed join to dia
  group_by(year) %>%
  summarise(sampling_events_count = n_distinct(sample_id))  %>%
   as.data.frame()

for(i in 1:2) {#should produce two figures next to each other
  barplot(event_counts[ ,2], names.arg = event_counts[ ,1], xlab="Year", ylab="Number of sampling events", main="Event counts per year")
}

##AS: or use ggplot
ggplot(dia, aes(x = year)) +
  geom_bar()



# Delete rows where cover was not measured but instead abundance
join_cov <- select(dia, taxon, sample_id, site_id, year, month, cover)
join_cov <- join_cov[complete.cases(join_cov), ]
# 39583 of 45980 entries remain
join_cov <- join_cov[!join_cov$cover=="0", ]
# 39270 entries remain

event_counts_cov <- join_cov %>%
  group_by(year) %>%
  summarise(sampling_events_count = n_distinct(sample_id))  %>%
   as.data.frame()

barplot(event_counts_cov[ ,2], names.arg = event_counts_cov[ ,1], xlab="Year", ylab="Number of sampling events", main="Event counts per year - Cover")

```

Samples per year
```{r  sampling-frequency, echo=TRUE, message=FALSE}
# count number of samples per year
# The species of each site are counted seperately
require(dplyr)

sample_counts <- dia %>%
  group_by(year) %>%
  summarise(sample_count = n()) %>%
  as.data.frame()

barplot(sample_counts[ ,2], names.arg = sample_counts[ ,1], xlab="Year", ylab="Number of samples", main=" Sample counts per year")

## Without rows where abundance was measured instead of cover

sample_counts_cov <- join_cov %>%
  group_by(year) %>%
  summarise(sampling_events_count = n())  %>%
   as.data.frame()

barplot(sample_counts_cov[ ,2], names.arg = sample_counts_cov[ ,1], xlab="Year", ylab="Number of samples", main="Samples per year - Cover")

```

Sampling frequency 2005
```{r  sampling-frequency-2005, echo=TRUE, message=FALSE}
require(dplyr)
# Only rows considered with cover column filled out

## 2005 ##
# Event counts
event_counts_2005 <- select(join_cov, sample_id, year, month) %>%
  filter(year==2005) %>%
  group_by(month) %>%
  summarise(sampling_count = n_distinct(sample_id))  %>%
   as.data.frame()
  
# for(i in 1:2) #should produce two figures next to each other
barplot(event_counts_2005[ ,2], names.arg = event_counts_2005[ ,1], xlab="Year", ylab="Number of sampling events", main="Event counts per month of 2005")

# Sample counts
# The species of each site are counted seperately
sample_counts_2005 <- select(join_cov, sample_id, year, month) %>%
  filter(year==2005) %>%
  group_by(month) %>%
  summarise(sampling_count = n())  %>%
   as.data.frame()
  
barplot(sample_counts_2005[ ,2], names.arg = sample_counts_2005[ ,1], xlab="Year", ylab="Number of samples", main="Samples per month of 2005")
```

Sampling frequency 2006
```{r  sampling-frequency-2006, echo=TRUE, message=FALSE}
require(dplyr)
# Only rows considered with cover column filled out

## 2006 ##
# Event counts
event_counts_2006 <- select(join_cov, sample_id, year, month) %>%
  filter(year==2006) %>%
  group_by(month) %>%
  summarise(sampling_count = n_distinct(sample_id))  %>%
   as.data.frame()
  
# for(i in 1:2) #should produce two figures next to each other
barplot(event_counts_2006[ ,2], names.arg = event_counts_2006[ ,1], xlab="Year", ylab="Number of sampling events", main="Event counts per month of 2006")

# Sample counts
# The species of each site are counted seperately
sample_counts_2006 <- select(join_cov, sample_id, year, month) %>%
  filter(year==2006) %>%
  group_by(month) %>%
  summarise(sampling_count = n())  %>%
   as.data.frame()
  
barplot(sample_counts_2006[ ,2], names.arg = sample_counts_2006[ ,1], xlab="Year", ylab="Number of samples", main="Samples per month of 2006")
```
Sampling frequency 2007
```{r  sampling-frequency-2007, echo=TRUE, message=FALSE}
require(dplyr)
# Only rows considered with cover column filled out

## 2007 ##
# Event counts
event_counts_2007 <- select(join_cov, sample_id, year, month) %>%
  filter(year==2007) %>%
  group_by(month) %>%
  summarise(sampling_count = n_distinct(sample_id))  %>%
   as.data.frame()
  
# for(i in 1:2) #should produce two figures next to each other
barplot(event_counts_2007[ ,2], names.arg = event_counts_2007[ ,1], xlab="Year", ylab="Number of sampling events", main="Event counts per month of 2007")

# Sample counts
# The species of each site are counted seperately
sample_counts_2007 <- select(join_cov, sample_id, year, month) %>%
  filter(year==2007) %>%
  group_by(month) %>%
  summarise(sampling_count = n())  %>%
   as.data.frame()
  
barplot(sample_counts_2007[ ,2], names.arg = sample_counts_2007[ ,1], xlab="Year", ylab="Number of samples", main="Samples per month of 2007")
```

Sampling frequency 2008
```{r  sampling-frequency-2008, echo=TRUE, message=FALSE}
require(dplyr)
# Only rows considered with cover column filled out

## 2008 ##
# Event counts
event_counts_2008 <- select(join_cov, sample_id, year, month) %>%
  filter(year==2008) %>%
  group_by(month) %>%
  summarise(sampling_count = n_distinct(sample_id))  %>%
   as.data.frame()
  
# for(i in 1:2) #should produce two figures next to each other
barplot(event_counts_2008[ ,2], names.arg = event_counts_2008[ ,1], xlab="Year", ylab="Number of sampling events", main="Event counts per month of 2008")

# Sample counts
# The species of each site are counted seperately
sample_counts_2008 <- select(join_cov, sample_id, year, month) %>%
  filter(year==2008) %>%
  group_by(month) %>%
  summarise(sampling_count = n())  %>%
   as.data.frame()
  
barplot(sample_counts_2008[ ,2], names.arg = sample_counts_2008[ ,1], xlab="Year", ylab="Number of samples", main="Samples per month of 2008")
```

Sampling frequency 2009
```{r  sampling-frequency-2009, echo=TRUE, message=FALSE}
require(dplyr)
# Only rows considered with cover column filled out

## 2009 ##
# Event counts
event_counts_2009 <- select(join_cov, sample_id, year, month) %>%
  filter(year==2009) %>%
  group_by(month) %>%
  summarise(sampling_count = n_distinct(sample_id))  %>%
   as.data.frame()
  
# for(i in 1:2) #should produce two figures next to each other
barplot(event_counts_2009[ ,2], names.arg = event_counts_2009[ ,1], xlab="Year", ylab="Number of sampling events", main="Event counts per month of 2009")

# Sample counts
# The species of each site are counted seperately
sample_counts_2009 <- select(join_cov, sample_id, year, month) %>%
  filter(year==2009) %>%
  group_by(month) %>%
  summarise(sampling_count = n())  %>%
   as.data.frame()
  
barplot(sample_counts_2009[ ,2], names.arg = sample_counts_2009[ ,1], xlab="Year", ylab="Number of samples", main="Samples per month of 2009")
```

Sampling frequency 2010
```{r  sampling-frequency-2010, echo=TRUE, message=FALSE}
require(dplyr)
# Only rows considered with cover column filled out

## 2010 ##
# Event counts
event_counts_2010 <- select(join_cov, sample_id, year, month) %>%
  filter(year==2010) %>%
  group_by(month) %>%
  summarise(sampling_count = n_distinct(sample_id))  %>%
   as.data.frame()
  
# for(i in 1:2) #should produce two figures next to each other
barplot(event_counts_2010[ ,2], names.arg = event_counts_2010[ ,1], xlab="Year", ylab="Number of sampling events", main="Event counts per month of 2010")

# Sample counts
# The species of each site are counted seperately
sample_counts_2010 <- select(join_cov, sample_id, year, month) %>%
  filter(year==2010) %>%
  group_by(month) %>%
  summarise(sampling_count = n())  %>%
   as.data.frame()
  
barplot(sample_counts_2010[ ,2], names.arg = sample_counts_2010[ ,1], xlab="Year", ylab="Number of samples", main="Samples per month of 2010")
```

Sampling frequency 2011
```{r  sampling-frequency-2011, echo=TRUE, message=FALSE}
require(dplyr)
# Only rows considered with cover column filled out

## 2011 ##
# Event counts
event_counts_2011 <- select(join_cov, sample_id, year, month) %>%
  filter(year==2011) %>%
  group_by(month) %>%
  summarise(sampling_count = n_distinct(sample_id))  %>%
   as.data.frame()
  
# for(i in 1:2) #should produce two figures next to each other
barplot(event_counts_2011[ ,2], names.arg = event_counts_2011[ ,1], xlab="Year", ylab="Number of sampling events", main="Event counts per month of 2011")

# Sample counts
# The species of each site are counted seperately
sample_counts_2011 <- select(join_cov, sample_id, year, month) %>%
  filter(year==2011) %>%
  group_by(month) %>%
  summarise(sampling_count = n())  %>%
   as.data.frame()
  
barplot(sample_counts_2011[ ,2], names.arg = sample_counts_2011[ ,1], xlab="Year", ylab="Number of samples", main="Samples per month of 2011")
```

Sampling frequency 2012
```{r  sampling-frequency-2012, echo=TRUE, message=FALSE}
require(dplyr)
# Only rows considered with cover column filled out

## 2012 ##
# Event counts
event_counts_2012 <- select(join_cov, sample_id, year, month) %>%
  filter(year==2012) %>%
  group_by(month) %>%
  summarise(sampling_count = n_distinct(sample_id))  %>%
   as.data.frame()
  
# for(i in 1:2) #should produce two figures next to each other
barplot(event_counts_2012[ ,2], names.arg = event_counts_2012[ ,1], xlab="Year", ylab="Number of sampling events", main="Event counts per month of 2012")

# Sample counts
# The species of each site are counted seperately
sample_counts_2012 <- select(join_cov, sample_id, year, month) %>%
  filter(year==2012) %>%
  group_by(month) %>%
  summarise(sampling_count = n())  %>%
   as.data.frame()
  
barplot(sample_counts_2012[ ,2], names.arg = sample_counts_2012[ ,1], xlab="Year", ylab="Number of samples", main="Samples per month of 2012")
```

Calculation of the minimal cover per month and site and taxon over all years together.
```{r  blank, echo=TRUE, message=FALSE}
dia <- select(join_cov, taxon, site_id, month, cover) %>%
  group_by(month, site_id, taxon) %>%
  summarise_each(funs(min_cover = min(cover), mean_cover = mean(cover), quantile(cover, 0.05), count = n())) %>%
  as.data.frame()
# dia has 34162 entries
# However, casting data from long to wide format would still not work since there are stillseveral combinations for site and species.

```

## CA
```{r  ca, echo=TRUE, message=FALSE}
require(vegan)
# conduct CA
spec_ca <- cca(spec_fin)
spec_ca
plot(spec_ca) # species scores as weighted averages of site scores.
chisq.test(spec_fin/sum(spec_sum))
# x-squared = inertia from aboce, p-values not important
plot(spec_ca, scaling =1) #site scores as weighted averages of species scores

# CA for all years seperately
spec_ca05 <- cca(spec_fin05)
plot(spec_ca05)
spec_ca06 <- cca(spec_fin06)
plot(spec_ca06)
spec_ca07 <- cca(spec_fin07)
plot(spec_ca07)
spec_ca08 <- cca(spec_fin08)
plot(spec_ca08)
spec_ca09 <- cca(spec_fin09)
plot(spec_ca09)
spec_ca10 <- cca(spec_fin10)
plot(spec_ca10)
spec_ca11 <- cca(spec_fin11)
plot(spec_ca11)
spec_ca12 <- cca(spec_fin12)
plot(spec_ca12)
# Arch effect not so visible, mostl< only on one side. Outliers make interpretation hard.
# Output could change depending on the aggregation method.
```

Creating a data frame
Code not needed at the moment, I keep it just in case.
```{r  create-data-frame, echo=TRUE, message=FALSE}
drv = dbDriver("PostgreSQL")
con = dbConnect(drv, dbname = DBname, user = DBuser, host = DBhost, port = DBport, password = DBpassword)

##AS: wouldn't keep such not needed code in the script. Put it somewhere else.

# Functions not needed at the moment but keep them anyways, just in case.

dia_sam_year = dbGetQuery(con, " SELECT *, 
                    EXTRACT(YEAR FROM dsam.date) AS year
                     FROM dia.dia_samples AS dsam
                    WHERE date >= '2005-01-01'
                    ")
dia_sam_year = dbGetQuery(con, " SELECT dsam.id_rs, dsam.id_pn, dsam.date, dsam.dv, dsam.iz_n, dsam.iz_b, dsam.cover, dsam.site_id, dsite.site_nr, 
                    EXTRACT(YEAR FROM dsam.date) AS year
                     FROM dia.dia_samples AS dsam
                     JOIN dia.dia_sites AS dsite 
                     ON dsam.site_id = dsite.site_id                  
                    WHERE date >= '2005-01-01'
                    ")

psm_sam_year = dbGetQuery(con, " SELECT  psam.sample_id, psam.site_id,psam.date, psam.qualifier, psam.value, psam.unit, var.name, var.cas, var.pgroup, var.psm_type, var.pan_class, psite.site_nr,
                    EXTRACT(YEAR FROM psam.date) AS year
                     FROM views.psm_samples_2005 AS psam
                      JOIN phch.phch_variables var 
                      ON var.variable_id = psam.variable_id
                      JOIN views.psm_sites_2005 AS psite 
                      ON psam.site_id = psite.site_id                    
                      WHERE date >= '2005-01-01'
                     AND var.psm_type = 'herbicide'
                    LIMIT 1000")

# Create the data frame
samples <- merge(dia_sam_year, psm_sam_year, by = c("site_nr","year"))
samples <- merge(dia_sam_year, psm_sam_year, by = "year")
samples2 <- merge(dia_sam_year, psm_sam_year, by = "site_nr")
# Works for year but not for site_nr.
#Error: cannot allocate vector of size 4.4 Gb -> if 100000 objects in both dataframes
# merge by site_id results in emtpy data
# results in empty data

dbDisconnect(con)
dbUnloadDriver(drv)
```


```{r  read-taxalisten-data, echo=TRUE, message=FALSE}
samples_taxon <- merge(dia_sam_year, diatom_dat, by.x="dv", by.y="DV")
diatom_dat1<- read.table("C_Proben_Taxalisten.txt",header=T,sep="\t",dec=".")

```


```{r get-variables, echo=TRUE, message=FALSE}
drv = dbDriver("PostgreSQL")
con = dbConnect(drv, dbname = DBname, user = DBuser, host = DBhost, port = DBport, password = DBpassword)


var_names = dbGetQuery(con, "SELECT DISTINCT var.name
                                FROM phch.phch_samples sam
                                JOIN phch.phch_variables var ON var.variable_id = sam.variable_id
                                ")
# Nitrit, Nitrat-Stickstoff, Kalium, Sichttiefe, Chlorid, Nitrat, Gesamt-Phosphor, Sauerstoffgehalt, Sauerstoffzehrung nach 5 (7) Tagen ohne Hemmer, Gesamt-Stickstoff, Stickstoff, Wasserstand (OFW), pH-Wert (Feld) Ammonium-Stickstoff, Sauerstoffzehrung nach 7 Tagen mit Hemmer, BSB5, sedimentiert, Sauerstoffzehrung nach 21 Tagen mit Hemmer, TrÃ¼bung (physiko-chem. Messung), Elektrische LeitfÃ¤higkeit (20Â°C), Nitrit-Stickstoff, Natrium, Sulfat, Ammonium, Abfluss, spektraler Absorptionskoeffizient 436nm, freie KohlensÃ¤ure, SauerstoffsÃ¤ttigung, Stickstoff, Hydrogenkarbonat, Eisen, Wassertemperatur, Magnesium, Gesamtphosphor als PO4, Phosphor, Chemischer Sauerstoffbedarf

dbDisconnect(con)
dbUnloadDriver(drv)
```

```{r load-ec50-data, echo=TRUE, message=FALSE}
drv = dbDriver("PostgreSQL")
con = dbConnect(drv, dbname = DBname, user = DBuser, host = DBhost, port = DBport, password = DBpassword)

ec50 = dbGetQuery(con, "SELECT variable_id, name, n_al, ec50_al_fr_min, ec50_al_fr_min_taxa, ec50_al_fr_perc20, ec50_al_fr_mean
                                FROM phch.phch_ec50
                                LIMIT 100
                                ")


dbDisconnect(con)
dbUnloadDriver(drv)
```